{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5f95dd",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cea0eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb0646dade147aa9ecbde495444c2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 20:51:55 INFO: Downloaded file to C:\\Users\\Admin\\stanza_resources\\resources.json\n",
      "2024-12-10 20:51:55 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-12-10 20:51:56 INFO: File exists: C:\\Users\\Admin\\stanza_resources\\en\\default.zip\n",
      "2024-12-10 20:51:58 INFO: Finished downloading models and saved to C:\\Users\\Admin\\stanza_resources\n",
      "2024-12-10 20:51:58 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608c6c4717d4458abe601c920e5a3707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 20:51:59 INFO: Downloaded file to C:\\Users\\Admin\\stanza_resources\\resources.json\n",
      "2024-12-10 20:51:59 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-12-10 20:51:59 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-12-10 20:51:59 INFO: Using device: cpu\n",
      "2024-12-10 20:51:59 INFO: Loading: tokenize\n",
      "2024-12-10 20:51:59 INFO: Loading: mwt\n",
      "2024-12-10 20:51:59 INFO: Loading: pos\n",
      "2024-12-10 20:52:00 INFO: Loading: lemma\n",
      "2024-12-10 20:52:00 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>tgt</th>\n",
       "      <th>src</th>\n",
       "      <th>ref</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>label</th>\n",
       "      <th>p(Hallucination)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't worry, it's only temporary.</td>\n",
       "      <td>Don't worry. It's only temporary.</td>\n",
       "      <td>Не волнуйся. Это только временно.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom is never where he should be.</td>\n",
       "      <td>Tom is never where he's supposed to be.</td>\n",
       "      <td>Тома никогда нет там, где он должен быть.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's hard for me to work with Tom.</td>\n",
       "      <td>I have trouble working with Tom.</td>\n",
       "      <td>Мне сложно работать с Томом.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Water, please.</td>\n",
       "      <td>I'd like some water.</td>\n",
       "      <td>Воду, пожалуйста.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I didn't expect Tom to betray me.</td>\n",
       "      <td>I didn't think that Tom would betray me.</td>\n",
       "      <td>Я не ожидал, что Том предаст меня.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  hyp  \\\n",
       "0   Don't worry, it's only temporary.   \n",
       "1    Tom is never where he should be.   \n",
       "2  It's hard for me to work with Tom.   \n",
       "3                      Water, please.   \n",
       "4   I didn't expect Tom to betray me.   \n",
       "\n",
       "                                        tgt  \\\n",
       "0         Don't worry. It's only temporary.   \n",
       "1   Tom is never where he's supposed to be.   \n",
       "2          I have trouble working with Tom.   \n",
       "3                      I'd like some water.   \n",
       "4  I didn't think that Tom would betray me.   \n",
       "\n",
       "                                         src     ref task model  \\\n",
       "0          Не волнуйся. Это только временно.  either   MT         \n",
       "1  Тома никогда нет там, где он должен быть.  either   MT         \n",
       "2               Мне сложно работать с Томом.  either   MT         \n",
       "3                          Воду, пожалуйста.  either   MT         \n",
       "4         Я не ожидал, что Том предаст меня.  either   MT         \n",
       "\n",
       "               label  p(Hallucination)  \n",
       "0  Not Hallucination              0.00  \n",
       "1  Not Hallucination              0.25  \n",
       "2  Not Hallucination              0.25  \n",
       "3      Hallucination              1.00  \n",
       "4  Not Hallucination              0.25  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import stanza\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "from stanza.utils.conll import CoNLL\n",
    "\n",
    "# Initialize Stanza NLP model\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,lemma,pos')\n",
    "\n",
    "# Load Datasets \n",
    "train_df = pd.read_json('data/labeled_data/labeled-train.model-agnostic.json')\n",
    "test_df = pd.read_json('data/labeled_data/labeled-test.model-agnostic.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59a44f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>src</th>\n",
       "      <th>label</th>\n",
       "      <th>p(Hallucination)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You're not alone, claire- -</td>\n",
       "      <td>You're not alone, Claire.</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who told you to throw acid at Vargas, hmmm?</td>\n",
       "      <td>Who told you to throw acid at Vargas, hmm?</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>♪ Where the pure angel merges with the antic s...</td>\n",
       "      <td>Where the pure angel merges with the antic Sphinx</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where is it written what is it I'm meant to be?</td>\n",
       "      <td>Where is it written what is it I'm meant to be</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We'll find the skipper and then we'll go home.</td>\n",
       "      <td>We'll find the skipper and then we'll go home.</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 hyp  \\\n",
       "0                        You're not alone, claire- -   \n",
       "1        Who told you to throw acid at Vargas, hmmm?   \n",
       "2  ♪ Where the pure angel merges with the antic s...   \n",
       "3    Where is it written what is it I'm meant to be?   \n",
       "4     We'll find the skipper and then we'll go home.   \n",
       "\n",
       "                                                 src              label  \\\n",
       "0                          You're not alone, Claire.  Not Hallucination   \n",
       "1         Who told you to throw acid at Vargas, hmm?  Not Hallucination   \n",
       "2  Where the pure angel merges with the antic Sphinx  Not Hallucination   \n",
       "3     Where is it written what is it I'm meant to be  Not Hallucination   \n",
       "4     We'll find the skipper and then we'll go home.  Not Hallucination   \n",
       "\n",
       "   p(Hallucination)  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for Specific Task\n",
    "def load_and_filter_data(df, task_type, column_to_keep1, column_to_keep2, column_to_keep3):\n",
    "    # Filter for the specified task type\n",
    "    df = df[df['task'].isin([task_type])].reset_index(drop=True)\n",
    "    \n",
    "    # Define columns to drop, keeping only \"hyp\" and the specified column (\"src\" or \"tgt\")\n",
    "    columns_to_drop = [col for col in df.columns if col not in ['hyp','label', column_to_keep1, column_to_keep2, column_to_keep3]]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load train, test, and validation datasets with specified task type and column to keep\n",
    "pg_train_df = load_and_filter_data(train_df, 'PG', 'src', 'label', 'p(Hallucination)')\n",
    "pg_test_df = load_and_filter_data(test_df, 'PG', 'src', 'label', 'p(Hallucination)')\n",
    "\n",
    "pg_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48dd7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Segmentation, Normalization, and Stopword Removal Function\n",
    "def normalize_text(text, remove_stopwords=False):\n",
    "    expanded_text = contractions.fix(text).lower()  # Expand contractions and lowercase\n",
    "    text_no_punctuation = re.sub(r'[^\\w\\s]', '', expanded_text) # Remove punctuation\n",
    "    \n",
    "    # Optionally remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        # Tokenize to remove stopwords and then join back to a single string\n",
    "        text_no_stopwords = ' '.join(word for word in text_no_punctuation.split() if word not in stop_words)\n",
    "        return text_no_stopwords\n",
    "    \n",
    "    return text_no_punctuation\n",
    "\n",
    "# Lemmatization Function\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [word.lemma for sentence in doc.sentences for word in sentence.words]\n",
    "\n",
    "# Apply Preprocessing Steps to Dataset\n",
    "def preprocess_dataset(df, column):\n",
    "    # Normalize text\n",
    "    df['hyp_normalized'] = df['hyp'].apply(normalize_text)\n",
    "    df[f'{column}_normalized'] = df[column].apply(normalize_text)\n",
    "    \n",
    "    # Sentence Segmentation\n",
    "    df['hyp_sentences'] = df['hyp_normalized'].apply(sent_tokenize)\n",
    "    df[f'{column}_sentences'] = df[f'{column}_normalized'].apply(sent_tokenize)\n",
    "    \n",
    "    # Tokenization\n",
    "    df['hyp_tokens'] = df['hyp_sentences'].apply(lambda sentences: [word_tokenize(sentence) for sentence in sentences])\n",
    "    df[f'{column}_tokens'] = df[f'{column}_sentences'].apply(lambda sentences: [word_tokenize(sentence) for sentence in sentences])\n",
    "    \n",
    "    # Lemmatization\n",
    "    df['hyp_lemmas'] = df['hyp_normalized'].apply(lemmatize_text)\n",
    "    df[f'{column}_lemmas'] = df[f'{column}_normalized'].apply(lemmatize_text)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# pg_train_df = preprocess_dataset(pg_train_df, 'src')\n",
    "# pg_test_df = preprocess_dataset(pg_test_df, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b81299d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved to data/labeled_data/preprocessed/pg_preprocessed_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed dataset to a CSV file\n",
    "preprocessed_file_path = \"data/labeled_data/preprocessed/pg_preprocessed_dataset.csv\"\n",
    "pg_train_df.to_csv(preprocessed_file_path, index=False)\n",
    "\n",
    "print(f\"Preprocessed dataset saved to {preprocessed_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b702f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Not Hallucination    5326\n",
      "Hallucination        4674\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(pg_train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff276650",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "**1. Importing Required Libraries**\n",
    "\n",
    "**2. Loading the Data**\n",
    "- Load the labeled dataset from the CSV file (`pg_train_label.csv`).\n",
    "- Remove any rows with missing values to ensure clean data.\n",
    "\n",
    "**3. Combining Text Features**\n",
    "- Combine the two columns (`hyp_lemmas` and `src_lemmas`) that are most likely the core inputs in our dataset for detecting hallucinations. By combining these columns, you're essentially merging the two key pieces of information that your model needs.\n",
    "- This merged text will be used as input for the model, as both columns may contain complementary information about the task.\n",
    "\n",
    "**4. Splitting the Data**\n",
    "- **`X`**: Features (in this case, the combined text data).\n",
    "- **`y`**: Labels (`label` column).\n",
    "\n",
    "**5. Converting Text to Numerical Features (TF-IDF Vectorization)**\n",
    "- **TF-IDF Vectorization**:\n",
    "  - Converts the text into numerical features by analyzing the importance of each word (or n-grams) in the document.\n",
    "  - **`ngram_range=(1, 2)`**: Includes single words (unigrams) and pairs of consecutive words (bigrams).\n",
    "  - **`max_features=5000`**: Limits the vocabulary to the top 5,000 most important words or phrases based on their TF-IDF score.\n",
    "- Apply the vectorizer to the training data (`fit_transform`) and the testing data (`transform`).\n",
    "\n",
    "**6. Training a Naive Bayes Classifier**\n",
    "- A **Multinomial Naive Bayes classifier** is initialized and trained using the vectorized training data (`X_train_vec`) and corresponding labels (`y_train`).\n",
    "- This algorithm is suitable for text classification problems as it assumes word frequencies follow a multinomial distribution.\n",
    "\n",
    "**7. Making Predictions**\n",
    "- Use the trained model to predict the labels for the test set (`X_test_vec`).\n",
    "\n",
    "**8. Evaluating the Model**\n",
    "- **`accuracy_score`**: Computes the percentage of correctly predicted labels in the test set.\n",
    "- **`classification_report`**: Provides a detailed evaluation of the model’s performance, including:\n",
    "  - **Precision**: How many of the predicted positives are true positives.\n",
    "  - **Recall**: How many of the actual positives were correctly identified.\n",
    "  - **F1-score**: Harmonic mean of precision and recall.\n",
    "  - **Support**: Number of actual occurrences for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0065ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.536\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Hallucination       0.63      0.44      0.52       212\n",
      "Not Hallucination       0.48      0.66      0.55       163\n",
      "\n",
      "         accuracy                           0.54       375\n",
      "        macro avg       0.55      0.55      0.54       375\n",
      "     weighted avg       0.56      0.54      0.53       375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Use preprocessed training and testing datasets\n",
    "train_data = pg_train_df.dropna()\n",
    "test_data = pg_test_df.dropna()\n",
    "\n",
    "# Combine `hyp_lemmas` and `src_lemmas` into a single text feature for both train and test sets\n",
    "train_data['combined_text'] = train_data['hyp_lemmas'].apply(lambda x: \" \".join(x)) + \" \" + train_data['src_lemmas'].apply(lambda x: \" \".join(x))\n",
    "test_data['combined_text'] = test_data['hyp_lemmas'].apply(lambda x: \" \".join(x)) + \" \" + test_data['src_lemmas'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_data['combined_text']\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data['combined_text']\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = naive_bayes.predict(X_test_vec)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c95fd",
   "metadata": {},
   "source": [
    "### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "334f59c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "Best Parameters: {'nb__alpha': 1.0, 'tfidf__max_features': 3000, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None}\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Hallucination       0.66      0.38      0.48       212\n",
      "Not Hallucination       0.48      0.75      0.59       163\n",
      "\n",
      "         accuracy                           0.54       375\n",
      "        macro avg       0.57      0.56      0.53       375\n",
      "     weighted avg       0.58      0.54      0.53       375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Use preprocessed training and testing datasets\n",
    "train_data = pg_train_df.dropna()\n",
    "test_data = pg_test_df.dropna()\n",
    "\n",
    "# Combine `hyp_lemmas` and `src_lemmas` into a single text feature for both train and test sets\n",
    "train_data['combined_text'] = train_data['hyp_lemmas'].apply(lambda x: \" \".join(x)) + \" \" + train_data['src_lemmas'].apply(lambda x: \" \".join(x))\n",
    "test_data['combined_text'] = test_data['hyp_lemmas'].apply(lambda x: \" \".join(x)) + \" \" + test_data['src_lemmas'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_data['combined_text']\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data['combined_text']\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  # Vectorizer\n",
    "    ('nb', MultinomialNB())       # Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [2000, 3000, 5000, 10000],  # Increase feature size\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],            # Focus on unigrams and bigrams\n",
    "    'tfidf__min_df': [1, 2, 3],                        # Tune minimum document frequency\n",
    "    'tfidf__stop_words': [None, stopwords.words('english')],  # Include stopword removal\n",
    "    'nb__alpha': [1.0, 0.5, 0.1, 0.01]                # Fine-tune smoothing\n",
    "}\n",
    "\n",
    "# Perform grid search with stratified cross-validation\n",
    "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=stratified_cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c986eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f4cfed7",
   "metadata": {},
   "source": [
    "This script appears to evaluate the performance of a sequence classification model for detecting hallucinations in text pairs. Below is a step-by-step explanation of what the script does:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Preparing Data**\n",
    "- **Loading Validation Data**:\n",
    "  ```python\n",
    "  data_val = open(\"data/val.model-agnostic.json\")\n",
    "  data = json.load(data_val)\n",
    "  df_val = pd.DataFrame(data)\n",
    "  df_dm = df_val[df_val[\"task\"] == \"DM\"]\n",
    "  ```\n",
    "  - Loads validation data from a JSON file.\n",
    "  - Converts the data into a DataFrame (`df_val`) and filters it for entries related to the task `\"DM\"`.\n",
    "  \n",
    "- **Loading Test Data**:\n",
    "  ```python\n",
    "  data_test = open(\"data/test.model-agnostic.json\")\n",
    "  data = json.load(data_test)\n",
    "  df_test = pd.DataFrame(data)\n",
    "  df_dm_test = df_test[df_test[\"task\"] == \"DM\"]\n",
    "  ```\n",
    "  - Similar to the validation data process, loads and filters test data for the `\"DM\"` task.\n",
    "\n",
    "- **Extracting True Labels**:\n",
    "  ```python\n",
    "  def extract_truelabels(df):\n",
    "      true_labels = []\n",
    "      for label in df[\"label\"]:\n",
    "          if label == \"Not Hallucination\":\n",
    "              true_labels.append(0)\n",
    "          else:\n",
    "              true_labels.append(1)\n",
    "      df[\"true_labels\"] = true_labels\n",
    "      return true_labels\n",
    "  ```\n",
    "  - Converts labels (`\"Not Hallucination\"` or `\"Hallucination\"`) into numeric values (`0` or `1`) for easier evaluation.\n",
    "  - Adds a `true_labels` column to the validation and test DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Functions for Model Evaluation**\n",
    "- **Assess Performance**:\n",
    "  ```python\n",
    "  def assess_performance(true_labels, pred_labels):\n",
    "      ...\n",
    "      accuracy = (tp + tn) / len(true_labels)\n",
    "      ...\n",
    "      return accuracy, precision, recall, f1\n",
    "  ```\n",
    "  - Calculates performance metrics for the classifier:\n",
    "    - **Accuracy**: Overall percentage of correct classifications.\n",
    "    - **Precision**: Proportion of true positives among predicted positives.\n",
    "    - **Recall**: Proportion of true positives among actual positives.\n",
    "    - **F1-Score**: Harmonic mean of precision and recall.\n",
    "  - Returns these metrics and prints them.\n",
    "\n",
    "- **Finding the Best Threshold**:\n",
    "  ```python\n",
    "  def finding_threshold(similarities):\n",
    "      ...\n",
    "      accs.append(acc)\n",
    "      ...\n",
    "      plt.plot(thresholds, accs, color=\"red\", label=\"accuracy\")\n",
    "      ...\n",
    "      return max_acc\n",
    "  ```\n",
    "  - Finds the best threshold for converting probabilities (or similarities) into binary predictions.\n",
    "  - Evaluates classifier performance over a range of thresholds (`0.0` to `1.0`) and returns the threshold with the highest accuracy.\n",
    "\n",
    "- **Get Predictions**:\n",
    "  ```python\n",
    "  def get_prediction(probs, thresh):\n",
    "      pred_labels = []\n",
    "      for sim in probs:\n",
    "          if sim > thresh:\n",
    "              pred_labels.append(0)\n",
    "          else:\n",
    "              pred_labels.append(1)\n",
    "      return pred_labels\n",
    "  ```\n",
    "  - Converts probabilities into binary predictions (`0` or `1`) based on a threshold.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Model Preparation**\n",
    "- **Input Preparation**:\n",
    "  ```python\n",
    "  sentences_hyp = df_dm[\"hyp\"]\n",
    "  sentences_tgt = df_dm[\"tgt\"]\n",
    "  pairs_val = [(hyp, tgt) for hyp, tgt in zip(sentences_hyp, sentences_tgt)]\n",
    "  ```\n",
    "  - Prepares pairs of hypothesis (`hyp`) and target (`tgt`) sentences for the validation data.\n",
    "\n",
    "- **Loading the Model**:\n",
    "  ```python\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(\n",
    "      'vectara/hallucination_evaluation_model', trust_remote_code=True)\n",
    "  ```\n",
    "  - Loads a pre-trained model for hallucination evaluation from the Hugging Face library.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Model Evaluation on Validation Data**\n",
    "- **Finding the Best Threshold**:\n",
    "  ```python\n",
    "  pred_vectara_val = model.predict(pairs_val)\n",
    "  thresh_vectara = finding_threshold(pred_vectara_val)\n",
    "  ```\n",
    "  - Runs the model on validation pairs to obtain probabilities or similarity scores.\n",
    "  - Finds the best threshold for classification by maximizing accuracy on the validation data.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Model Testing**\n",
    "- **Testing on Test Data**:\n",
    "  ```python\n",
    "  pairs_test = [(hyp, tgt) for hyp, tgt in zip(sentences_hyp_test, sentences_tgt_test)]\n",
    "  pred_vectara_test = model.predict(pairs_test)\n",
    "  labels_vectara_test = get_prediction(pred_vectara_test, thresh_vectara)\n",
    "  ```\n",
    "  - Prepares hypothesis-target pairs for the test data.\n",
    "  - Runs the model to get predictions for the test pairs.\n",
    "  - Converts these predictions into binary labels (`0` or `1`) using the best threshold (`thresh_vectara`).\n",
    "\n",
    "- **Assessing Test Performance**:\n",
    "  ```python\n",
    "  print(\"Performance of Vectara on Test Data:\")\n",
    "  assess_performance(true_labels_test, labels_vectara_test)\n",
    "  ```\n",
    "  - Evaluates the test set performance using accuracy, precision, recall, and F1-score metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "This script performs the following steps:\n",
    "1. Prepares validation and test datasets for the `\"DM\"` task by filtering relevant pairs and extracting true labels.\n",
    "2. Implements functions to evaluate performance, find the best classification threshold, and convert probabilities to binary predictions.\n",
    "3. Loads a pre-trained model (`vectara/hallucination_evaluation_model`) for hallucination evaluation.\n",
    "4. Uses the validation set to find the best threshold for classification.\n",
    "5. Tests the model on unseen test data and evaluates its performance using classification metrics.\n",
    "\n",
    "If you have additional questions or need refinements for specific sections, let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d8f79f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OfflineModeIsEnabled' from 'huggingface_hub.utils' (C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m###################### preparing data #########################\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# loading validation data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\__init__.py:72\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     31\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     38\u001b[0m     ContextManagers,\n\u001b[0;32m     39\u001b[0m     ExplicitEnum,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     71\u001b[0m )\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     73\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     74\u001b[0m     HF_MODULES_CACHE,\n\u001b[0;32m     75\u001b[0m     HUGGINGFACE_CO_PREFIX,\n\u001b[0;32m     76\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[0;32m     77\u001b[0m     PYTORCH_PRETRAINED_BERT_CACHE,\n\u001b[0;32m     78\u001b[0m     PYTORCH_TRANSFORMERS_CACHE,\n\u001b[0;32m     79\u001b[0m     S3_BUCKET_PREFIX,\n\u001b[0;32m     80\u001b[0m     TRANSFORMERS_CACHE,\n\u001b[0;32m     81\u001b[0m     TRANSFORMERS_DYNAMIC_MODULE_NAME,\n\u001b[0;32m     82\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     83\u001b[0m     PushInProgress,\n\u001b[0;32m     84\u001b[0m     PushToHubMixin,\n\u001b[0;32m     85\u001b[0m     RepositoryNotFoundError,\n\u001b[0;32m     86\u001b[0m     RevisionNotFoundError,\n\u001b[0;32m     87\u001b[0m     cached_file,\n\u001b[0;32m     88\u001b[0m     default_cache_path,\n\u001b[0;32m     89\u001b[0m     define_sagemaker_information,\n\u001b[0;32m     90\u001b[0m     download_url,\n\u001b[0;32m     91\u001b[0m     extract_commit_hash,\n\u001b[0;32m     92\u001b[0m     get_cached_models,\n\u001b[0;32m     93\u001b[0m     get_file_from_repo,\n\u001b[0;32m     94\u001b[0m     has_file,\n\u001b[0;32m     95\u001b[0m     http_user_agent,\n\u001b[0;32m     96\u001b[0m     is_offline_mode,\n\u001b[0;32m     97\u001b[0m     is_remote_url,\n\u001b[0;32m     98\u001b[0m     move_cache,\n\u001b[0;32m     99\u001b[0m     send_example_telemetry,\n\u001b[0;32m    100\u001b[0m     try_to_load_from_cache,\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    103\u001b[0m     ACCELERATE_MIN_VERSION,\n\u001b[0;32m    104\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m     torch_only_method,\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    238\u001b[0m     ADAPTER_CONFIG_NAME,\n\u001b[0;32m    239\u001b[0m     ADAPTER_SAFE_WEIGHTS_NAME,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     find_adapter_config_file,\n\u001b[0;32m    243\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:49\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m     _CACHED_NO_EXIST,\n\u001b[0;32m     36\u001b[0m     CommitOperationAdd,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     try_to_load_from_cache,\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m REGEX_COMMIT_HASH, http_get\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     51\u001b[0m     GatedRepoError,\n\u001b[0;32m     52\u001b[0m     HfHubHTTPError,\n\u001b[0;32m     53\u001b[0m     HFValidationError,\n\u001b[0;32m     54\u001b[0m     LocalEntryNotFoundError,\n\u001b[0;32m     55\u001b[0m     OfflineModeIsEnabled,\n\u001b[0;32m     56\u001b[0m     RepositoryNotFoundError,\n\u001b[0;32m     57\u001b[0m     RevisionNotFoundError,\n\u001b[0;32m     58\u001b[0m     build_hf_headers,\n\u001b[0;32m     59\u001b[0m     get_session,\n\u001b[0;32m     60\u001b[0m     hf_raise_for_status,\n\u001b[0;32m     61\u001b[0m     send_telemetry,\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_deprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_method\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OfflineModeIsEnabled' from 'huggingface_hub.utils' (C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "###################### preparing data #########################\n",
    "\n",
    "# loading validation data\n",
    "data_val = open(\"data/val.model-agnostic.json\")\n",
    "data = json.load(data_val)\n",
    "df_val = pd.DataFrame(data)\n",
    "df_dm = df_val[df_val[\"task\"] == \"PG\"]\n",
    "\n",
    "\n",
    "# loading test data\n",
    "data_test = open(\"data/test.model-agnostic.json\")\n",
    "data = json.load(data_test)\n",
    "df_test = pd.DataFrame(data)\n",
    "df_dm_test = df_test[df_test[\"task\"] == \"PG\"]\n",
    "\n",
    "pg_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d71ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extracting true labels\n",
    "def extract_truelabels(df):\n",
    "\n",
    "    true_labels= []\n",
    "\n",
    "    for label in df[\"label\"]:\n",
    "\n",
    "        # 0 for not Hallucination, 1 for Hallucination\n",
    "\n",
    "        if label == \"Not Hallucination\":\n",
    "            true_labels.append(0)\n",
    "\n",
    "        else:\n",
    "            true_labels.append(1)\n",
    "\n",
    "    df[\"true_labels\"] = true_labels\n",
    "    return true_labels\n",
    "\n",
    "true_labels_val = extract_truelabels(df_dm)\n",
    "true_labels_test = extract_truelabels(df_dm_test)\n",
    "\n",
    "\n",
    "\n",
    "################### Functions to Choose and Evaluate Model ############################\n",
    "\n",
    "\n",
    "# function to assess performance of classifier\n",
    "\n",
    "def assess_performance(true_labels, pred_labels):\n",
    "\n",
    "    # initialize counter for the correct vs. incorrect classifications\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "\n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "\n",
    "        if true == 1 and pred == 1:\n",
    "            tp += 1\n",
    "        elif true == 1 and pred == 0:\n",
    "            fn += 1\n",
    "        elif true == 0 and pred == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    accuracy = (tp + tn) / len(true_labels)\n",
    "    try:\n",
    "        precision = tp / (tp + fp)\n",
    "    except:\n",
    "        precision = 0\n",
    "    recall = tp / (tp + fn)\n",
    "    try:\n",
    "       f1 = 2* (precision * recall) / (precision + recall)\n",
    "    except:\n",
    "        f1 = 0\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-Score:\", f1)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "# function for finding best threshold on validation data\n",
    "\n",
    "def finding_threshold(similarities):\n",
    "\n",
    "    # now testing which threshold leads to the highest accuracy\n",
    "    accs = []\n",
    "    recs = []\n",
    "    precs = []\n",
    "\n",
    "    # defining thresholds\n",
    "    thresholds = np.linspace(0, 1, 20).tolist()\n",
    "\n",
    "\n",
    "    for thresh in thresholds:\n",
    "\n",
    "        # convert similarities to a label based on threshold\n",
    "        pred_label = []\n",
    "\n",
    "        for sim in similarities:\n",
    "\n",
    "            if sim > thresh:\n",
    "                pred_label.append(0)\n",
    "\n",
    "            else:\n",
    "                pred_label.append(1)\n",
    "\n",
    "        # calculate performance based on threshold\n",
    "        acc, prec, rec, f1 = assess_performance(true_labels_val, pred_label)\n",
    "        accs.append(acc)\n",
    "        recs.append(rec)\n",
    "        precs.append(prec)\n",
    "\n",
    "\n",
    "    \n",
    "    # return threshold with highest accuracy\n",
    "    max_acc = thresholds[accs.index(max(accs))]\n",
    "    print(\"highest accuracy at a threshold of:\", max_acc)\n",
    "    \n",
    "    plt.plot(thresholds, accs, color = \"red\", label = \"accuracy\")\n",
    "    plt.plot(thresholds, precs, color = \"green\", label = \"precision\")\n",
    "    plt.plot(thresholds, recs, color = \"blue\", label = \"recall\")\n",
    "    plt.legend()\n",
    "    plt.axvline(max_acc, color = \"grey\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return(max_acc)\n",
    "\n",
    "\n",
    "\n",
    "# Function to transform probabilities into labels\n",
    " \n",
    "def get_prediction(probs, thresh):\n",
    "\n",
    "    pred_labels = []\n",
    "\n",
    "    for sim in probs:\n",
    "\n",
    "        if sim > thresh:\n",
    "            pred_labels.append(0)\n",
    "\n",
    "        else:\n",
    "            pred_labels.append(1)\n",
    "\n",
    "    return pred_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################### Defining Model ##############################\n",
    "\n",
    "# prepating input\n",
    "sentences_hyp = df_dm[\"hyp\"]\n",
    "sentences_tgt = df_dm[\"tgt\"]\n",
    "\n",
    "pairs_val = [(hyp, tgt) for hyp, tgt in zip(sentences_hyp, sentences_tgt)]\n",
    "\n",
    "# loading model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'vectara/hallucination_evaluation_model', trust_remote_code=True)\n",
    "\n",
    "# finding best model based on validation data\n",
    "pred_vectara_val = model.predict(pairs_val)\n",
    "thresh_vectara = finding_threshold(pred_vectara_val)\n",
    "\n",
    "\n",
    "# now testing model\n",
    "sentences_hyp_test = df_dm_test[\"hyp\"]\n",
    "sentences_tgt_test = df_dm_test[\"tgt\"]\n",
    "\n",
    "pairs_test = [(hyp, tgt) for hyp, tgt in zip(sentences_hyp_test, sentences_tgt_test)]\n",
    "\n",
    "pred_vectara_test = model.predict(pairs_test)\n",
    "\n",
    "labels_vectara_test = get_prediction(pred_vectara_test, thresh_vectara)\n",
    "print(\"Performance of Vectara on Test Data:\")\n",
    "assess_performance(true_labels_test, labels_vectara_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd9fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
